{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ad30fe2-1fc1-47e3-8a9f-624170b5aae6"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYYdTBQoKeCP"
   },
   "source": [
    " # Vertex AI Model Garden - Segment Anything Model (SAM) Serving on Vertex AI\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_sam.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_sam.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/community/model_garden/model_garden_pytorch_sam.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "Open in Vertex AI Workbench\n",
    "    </a>\n",
    "    (a Python-3 CPU notebook is recommended)\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbmPgTp2LRCY"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook demonstrates using the [huggingface/transformers](https://github.com/huggingface/transformers) framework to serve Segment Anything Model (SAM) models and deploy them for online prediction on Vertex AI.\n",
    "\n",
    "Following the notebook you will conduct experiments using the pre-built docker image on Vertex AI.\n",
    "\n",
    "- With the pre-built docker images, you can **deploy** models for the following tasks:\n",
    "    - Mask Generation\n",
    "\n",
    "### Objective\n",
    "\n",
    "- Upload the model to [Model Registry](https://cloud.google.com/vertex-ai/docs/model-registry/introduction).\n",
    "- Deploy the model on [Endpoint](https://cloud.google.com/vertex-ai/docs/predictions/using-private-endpoints).\n",
    "- Run online predictions for image captioning.\n",
    "\n",
    "### Costs\n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78f72e0a-52e5-4de5-ac0f-2171b3493825"
   },
   "source": [
    "## Setup environment\n",
    "\n",
    "**NOTE**: Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$` into these commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G__krby2Mqmh"
   },
   "source": [
    "### Colab only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898
    },
    "executionInfo": {
     "elapsed": 25230,
     "status": "ok",
     "timestamp": 1734632572159,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "RS5_6QVFMyc-",
    "outputId": "0b128ad3-7bf7-4b2c-ef60-9c3e1c119bb9"
   },
   "outputs": [],
   "source": [
    "!pip3 install --upgrade google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1734632572159,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "Li2aj1n9NDYl",
    "outputId": "d8014d0c-02cb-43a6-a444-62f287148d51"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth as google_auth\n",
    "\n",
    "google_auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6c1bc20-3495-448a-b242-01930ba8153c"
   },
   "source": [
    "### Setup Google Cloud project\n",
    "\n",
    "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
    "\n",
    "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
    "\n",
    "1. [Enable the Vertex AI API and Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component).\n",
    "\n",
    "1. [Create a Cloud Storage bucket](https://cloud.google.com/storage/docs/creating-buckets) for storing experiment outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5b1f2c08-c84e-4158-a976-e6b59d1055ca"
   },
   "source": [
    "It's highly recommended to run this notebook on [Vertex AI workbench](https://cloud.google.com/vertex-ai-workbench)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fc1fc14-2d77-4bf7-8f6d-c1afc10c848a"
   },
   "source": [
    "If you are running this notebook locally, you will need to install the [Cloud SDK](https://cloud.google.com/sdk) and [gsutil](https://cloud.google.com/storage/docs/gsutil_install)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e02b9811-b730-4573-83fa-9d47f2ce0436"
   },
   "source": [
    "####Fill following variables for experiments environment:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 173,
     "status": "ok",
     "timestamp": 1734632684829,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "7c2ce2fa-5a9b-40f6-b99d-6c1325775b36"
   },
   "outputs": [],
   "source": [
    "# Cloud project id.\n",
    "PROJECT_ID = \"ai-ml-team-sandbox\"  # @param {type:\"string\"}\n",
    "\n",
    "# The region you want to launch jobs in.\n",
    "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "# The Cloud Storage bucket for storing experiments output. Fill it without the 'gs://' prefix.\n",
    "GCS_BUCKET = \"okeefe_roll20_test\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwgeVkFXOS64"
   },
   "source": [
    "*Initialize* Vertex AI API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1734632689278,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "MxqnJMahPK8r"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSjMVyG8PYS-"
   },
   "source": [
    "### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 185,
     "status": "ok",
     "timestamp": 1734632697470,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "H05BzPO5Pcnh"
   },
   "outputs": [],
   "source": [
    "# The pre-built serving docker image.\n",
    "# The model artifacts are embedded within the container, except for model weights which will be downloaded during deployment.\n",
    "SERVE_DOCKER_URI = (\n",
    "    \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/sam-serve\"\n",
    ")\n",
    "\n",
    "# The serving port.\n",
    "SERVE_PORT = 7080\n",
    "\n",
    "# The serving route.\n",
    "SERVE_ROUTE = \"/predictions/sam_serving\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82058975-23b5-4b97-9e14-dd9a29c578ed"
   },
   "source": [
    "### Define common utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1734632701928,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "a78f988d-e5e2-4a57-ba0f-569e970514c0"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pycocotools.mask as mask_util\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def download_image(url):\n",
    "    response = requests.get(url)\n",
    "    return Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "\n",
    "def image_to_base64(image):\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format=\"JPEG\")\n",
    "    image_str = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "    return image_str\n",
    "\n",
    "\n",
    "def base64_to_image(image_str):\n",
    "    image = Image.open(BytesIO(base64.b64decode(image_str)))\n",
    "    return image\n",
    "\n",
    "\n",
    "def image_grid(imgs, rows=2, cols=2):\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
    "    return grid\n",
    "\n",
    "\n",
    "def draw_image_with_boxes(image, boxes):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(image)\n",
    "    for box in boxes:\n",
    "        x, y = box[\"xmin\"], box[\"ymin\"]\n",
    "        width, height = box[\"xmax\"] - x, box[\"ymax\"] - y\n",
    "        rect = patches.Rectangle(\n",
    "            (x, y), width, height, linewidth=2, edgecolor=\"yellow\", facecolor=\"none\"\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def decode_rle_masks(pred_masks_rle):\n",
    "    return np.stack([mask_util.decode(rle) for rle in pred_masks_rle])\n",
    "\n",
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30 / 255, 144 / 255, 255 / 255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "\n",
    "def show_predictions(preds):\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "    fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(np.array(image1))\n",
    "    ax = plt.gca()\n",
    "    masks = decode_rle_masks(preds[0][\"masks_rle\"])\n",
    "    for mask in masks:\n",
    "        show_mask(mask, ax=ax, random_color=True)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    fig.add_subplot(1, 2, 2)\n",
    "    plt.imshow(np.array(image2))\n",
    "    ax = plt.gca()\n",
    "    masks = decode_rle_masks(preds[1][\"masks_rle\"])\n",
    "    for mask in masks:\n",
    "        show_mask(mask, ax=ax, random_color=True)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def deploy_model(task, model_id):\n",
    "    endpoint = aiplatform.Endpoint.create(display_name=f\"{task}-endpoint\")\n",
    "    serving_env = {\n",
    "        \"MODEL_ID\": model_id,\n",
    "        \"TASK\": task,\n",
    "        \"DEPLOY_SOURCE\": \"notebook\",\n",
    "    }\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=task,\n",
    "        serving_container_image_uri=SERVE_DOCKER_URI,\n",
    "        serving_container_ports=[SERVE_PORT],\n",
    "        serving_container_predict_route=SERVE_ROUTE,\n",
    "        serving_container_health_route=\"/ping\",\n",
    "        serving_container_environment_variables=serving_env,\n",
    "    )\n",
    "    model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        machine_type=\"n1-standard-8\",\n",
    "        accelerator_type=\"NVIDIA_TESLA_V100\",\n",
    "        accelerator_count=1,\n",
    "        deploy_request_timeout=1800,\n",
    "    )\n",
    "    return endpoint, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "242fc8cf-5a0e-483b-8c9d-77a474cedc4b"
   },
   "source": [
    "## Mask Generation with Vertex AI Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xEESBROV4SMR"
   },
   "outputs": [],
   "source": [
    "def predict_custom_trained_model_sample(\n",
    "    project: str,\n",
    "    endpoint_id: str,\n",
    "    instances: Union[Dict, List[Dict]],\n",
    "    location: str = \"us-central1\",\n",
    "    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "):\n",
    "    \"\"\"\n",
    "    `instances` can be either single instance of type dict or a list\n",
    "    of instances.\n",
    "    \"\"\"\n",
    "    # The AI Platform services require regional API endpoints.\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    # This client only needs to be created once, and can be reused for multiple requests.\n",
    "    client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
    "    # The format of each instance should conform to the deployed model's prediction input schema.\n",
    "    instances = instances if isinstance(instances, list) else [instances]\n",
    "    instances = [\n",
    "        json_format.ParseDict(instance_dict, Value()) for instance_dict in instances\n",
    "    ]\n",
    "    parameters_dict = {}\n",
    "    parameters = json_format.ParseDict(parameters_dict, Value())\n",
    "    endpoint = client.endpoint_path(\n",
    "        project=project, location=location, endpoint=endpoint_id\n",
    "    )\n",
    "    response = client.predict(\n",
    "        endpoint=endpoint, instances=instances, parameters=parameters\n",
    "    )\n",
    "    print(\"response\")\n",
    "    print(\" deployed_model_id:\", response.deployed_model_id)\n",
    "    # The predictions are a google.protobuf.Value representation of the model's predictions.\n",
    "    predictions = response.predictions\n",
    "    for prediction in predictions:\n",
    "        print(\" prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3LmXZOi4aij"
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List, Union\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "\n",
    "client_options = {\"api_endpoint\": \"us-central1-aiplatform.googleapis.com\"}\n",
    "project=\"741027775203\"\n",
    "endpoint_id=\"7011868224815890432\"\n",
    "location=\"us-central1\"\n",
    "\n",
    "client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
    "\n",
    "endpoint = client.endpoint_path(\n",
    "    project=project, location=location, endpoint=endpoint_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 468779,
     "status": "ok",
     "timestamp": 1734633191897,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "ot2HhTqxRYri",
    "outputId": "a7e4a8f0-f16d-48af-f79a-3ea75be719eb"
   },
   "outputs": [],
   "source": [
    "# endpoint, model = deploy_model(\n",
    "#     task=\"mask-generation\", model_id=\"facebook/sam-vit-large\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "executionInfo": {
     "elapsed": 1383,
     "status": "ok",
     "timestamp": 1734635108781,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "_oXU9Osv5Eod",
    "outputId": "9c453d80-7a85-4883-a21f-a992ba1e7a7a"
   },
   "outputs": [],
   "source": [
    "image1 = download_image(\"http://images.cocodataset.org/val2017/000000039769.jpg\")\n",
    "image2 = download_image(\"http://images.cocodataset.org/val2017/000000000285.jpg\")\n",
    "grid = image_grid([image1, image2], 1, 2)\n",
    "display(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "executionInfo": {
     "elapsed": 238,
     "status": "error",
     "timestamp": 1734635187997,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "SdoF_Vik5Lp3",
    "outputId": "b7778ef5-ee90-494a-d5b5-87b25f6debb0"
   },
   "outputs": [],
   "source": [
    "instances = [\n",
    "    {\"image\": image_to_base64(image1)}#,\n",
    "    # {\"image\": image_to_base64(image2)},\n",
    "]\n",
    "response = client.predict(\n",
    "        endpoint=endpoint, instances=instances\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "executionInfo": {
     "elapsed": 14433,
     "status": "ok",
     "timestamp": 1734635261806,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "d6e51c57-b5e2-4ae7-888a-5391cceee5fb",
    "outputId": "8b522f33-54ab-4702-99a5-d2c4dd60f4af"
   },
   "outputs": [],
   "source": [
    "image1 = download_image(\"http://images.cocodataset.org/val2017/000000039769.jpg\")\n",
    "image2 = download_image(\"http://images.cocodataset.org/val2017/000000000285.jpg\")\n",
    "grid = image_grid([image1, image2], 1, 2)\n",
    "display(grid)\n",
    "\n",
    "instances = [\n",
    "    {\"image\": image_to_base64(image1)},\n",
    "    {\"image\": image_to_base64(image2)},\n",
    "]\n",
    "preds = endpoint.predict(instances=instances).predictions\n",
    "show_predictions(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 184,
     "status": "ok",
     "timestamp": 1734635281149,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "heObKl6GUcCd",
    "outputId": "ce8b0792-985d-445a-bafc-d985e5442966"
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UdquXMWR1E4"
   },
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1734636063710,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "XS81SE7JItte"
   },
   "outputs": [],
   "source": [
    "masks = decode_rle_masks(preds_new[1][\"masks_rle\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "id": "1ytdFVNzVSW5",
    "outputId": "f5d4758d-0284-40e1-e0f0-bdce2d3318ac"
   },
   "outputs": [],
   "source": [
    "# prompt: For each map, render just the image it covers from image1\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def apply_mask(image, mask):\n",
    "    \"\"\"Apply a binary mask to an image, making the masked region transparent.\"\"\"\n",
    "    image = image.convert(\"RGBA\")\n",
    "    mask_array = np.array(mask) * 255\n",
    "    mask_image = Image.fromarray(mask_array).convert(\"L\")\n",
    "    image.putalpha(mask_image)\n",
    "    return image\n",
    "\n",
    "masked_images = []\n",
    "for mask in masks:\n",
    "    masked_image = apply_mask(image2.copy(), mask)\n",
    "    masked_images.append(masked_image)\n",
    "\n",
    "# Display the masked images\n",
    "for masked_image in masked_images:\n",
    "    display(masked_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5284,
     "status": "ok",
     "timestamp": 1734635463881,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "_V_6XgDcUtyv",
    "outputId": "0608ee29-4520-455e-d9a7-940c9679d2dc"
   },
   "outputs": [],
   "source": [
    "for idx, mask in enumerate(masks):\n",
    "  print(f\"IDX: {idx}\")\n",
    "  plt.imshow(mask)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TGTWIJK8R136"
   },
   "outputs": [],
   "source": [
    "# Undeploy model and delete endpoint.\n",
    "endpoint.delete(force=True)\n",
    "\n",
    "# Delete models.\n",
    "model.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2.service_account import Credentials\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "# Path to your downloaded key file\n",
    "key_path = '../../key.json'\n",
    "\n",
    "# Create credentials object\n",
    "credentials = Credentials.from_service_account_file(\n",
    "    key_path,\n",
    "    scopes=['https://www.googleapis.com/auth/cloud-platform']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 170,
     "status": "ok",
     "timestamp": 1734635899789,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "ZEyy1ZgHWXTl"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# Initialize the Vertex AI SDK\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, credentials=credentials)\n",
    "\n",
    "ENDPOINT_ID = \"3156786943786745856\"\n",
    "\n",
    "# Create endpoint object from existing endpoint\n",
    "endpoint = aiplatform.Endpoint(\n",
    "    endpoint_name=f\"projects/{PROJECT_ID}/locations/{REGION}/endpoints/{ENDPOINT_ID}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "image_map = Image.open('../../found_maps/alley_battle_map.jpeg')\n",
    "instances = [\n",
    "    {\"image\": image_to_base64(image_map)},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9174,
     "status": "ok",
     "timestamp": 1734635932242,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "owXrvid_W0no"
   },
   "outputs": [],
   "source": [
    "preds_new = endpoint.predict(instances=instances).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(preds_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 162,
     "status": "ok",
     "timestamp": 1734635938631,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "BTvmpMTLW6Wq"
   },
   "outputs": [],
   "source": [
    "masks = decode_rle_masks(preds_new[0][\"masks_rle\"])\n",
    "\n",
    "masked_images = []\n",
    "for mask in masks:\n",
    "    masked_image = apply_mask(image_map.copy(), mask)\n",
    "    masked_images.append(masked_image)\n",
    "\n",
    "# # Display the masked images\n",
    "# for masked_image in masked_images:\n",
    "#     display(masked_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aykG4YHkW-Gx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "model_garden_pytorch_sam.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
